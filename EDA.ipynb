{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload  \n",
    "%autoreload 2 \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import octopus\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/garylai/Desktop/kaggle/petfinder/octopus/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(octopus.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config: \n",
    "    debug = True\n",
    "    epochs = 5\n",
    "    batch_size = 4\n",
    "    image_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data\"\n",
    "df_train = pd.read_csv(f'{data_path}/train.csv')\n",
    "if Config.debug: \n",
    "    df_train = df_train[:8]\n",
    "train_img_paths = [f\"{data_path}/train/{id}.jpg\" for id in df_train[\"Id\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug = train_aug = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(Config.image_size, Config.image_size, p=1),\n",
    "        albumentations.HueSaturationValue(\n",
    "            hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5\n",
    "        ),\n",
    "        albumentations.RandomBrightnessContrast(\n",
    "            brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5\n",
    "        ),\n",
    "        albumentations.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ],\n",
    "    p=1.0,\n",
    ")\n",
    "\n",
    "dense_features = [\n",
    "    'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "    'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n",
    "]\n",
    "\n",
    "train_ds = PawpularDataset(\n",
    "    image_paths=train_img_paths,\n",
    "    dense_features=df_train[dense_features].values,\n",
    "    targets=df_train.Pawpularity.values,\n",
    "    augmentation=train_aug\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=Config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': torch.Size([4, 256, 256, 3]), 'dense_features': torch.Size([4, 12]), 'target': torch.Size([4])}\n",
      "{'image': torch.Size([4, 256, 256, 3]), 'dense_features': torch.Size([4, 12]), 'target': torch.Size([4])}\n"
     ]
    }
   ],
   "source": [
    "# examine the batches\n",
    "for x in train_dl:\n",
    "    print({\n",
    "        \"image\": x['image'].shape,\n",
    "        \"dense_features\": x['dense_features'].shape,\n",
    "        \"target\": x[\"target\"].shape\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = timm.create_model(\"tf_efficientnet_b0_ns\", pretrained=True, in_chans=3).classifier; print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ProgressBar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-2dcaf65eedc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPawpularModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mProgressBar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrackLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"pawpular\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLrRecorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ProgressBar' is not defined"
     ]
    }
   ],
   "source": [
    "model = PawpularModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [octopus.ProgressBar(), octopus.TrackLoss(save_model=False, path=\"\", model_name=f\"pawpular\"), octopus.LrRecorder(len(param_groups))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    valid_dataset=train_ds,\n",
    "    train_bs=Config.batch_size,\n",
    "    valid_bs=2*Config.batch_size,\n",
    "    device=\"cpu\",\n",
    "    epochs=Config.epochs,\n",
    "    # callbacks=[es],\n",
    "    # fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ace8a33e05c733f72126e43fb40b6e204ac2b6d9be2e13bfeee82d1e3f4c0cc0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('commonlit': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
